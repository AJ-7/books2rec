{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from surprise import Reader, Dataset, SVD, evaluate, dump, accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Custom libraries\n",
    "sys.path.append('../Util')\n",
    "from loader import get_books, get_book_dataframe, get_book_features\n",
    "from joiner import get_ratings, get_joint, load_amazon, load_goodreads\n",
    "from reduction import reduce_matrix, get_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(user_to_concept, V, user_bias):\n",
    "    pred_ratings = np.zeros(len(V))\n",
    "    for i in range(len(V)):\n",
    "        pred = new_user_bias + np.dot(new_user_P, qi[i])\n",
    "        pred_ratings[i] = pred\n",
    "    return pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recs(result, books, n, q):\n",
    "    recs = []\n",
    "    for i in range(len(result)):\n",
    "        if q[i] == 0: # book user hasn't already rated\n",
    "            recs.append((i, result[i]))\n",
    "        else:\n",
    "            recs.append((i, float('-inf'))) \n",
    "            # recs.append((i, result[i])) #leave this to verify things actually working\n",
    "    recs = sorted(recs, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    top_titles = []\n",
    "    for i in range(n):\n",
    "        book_id = recs[i][0]\n",
    "        title = books.iloc[book_id]['title']\n",
    "        top_titles.append(title)\n",
    "    return top_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to where you save and load all data\n",
    "data_path = '../../goodbooks-10k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found books_dataframe in file...\n"
     ]
    }
   ],
   "source": [
    "# Get dataframe from books\n",
    "books = get_book_dataframe(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../.tmp/svd_100_300.npy'\n",
    "qi = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user from goodreads\n",
    "sparse_q = scipy.sparse.load_npz('../.tmp/cached_users/user_nickgreenquist.npz')\n",
    "q = sparse_q.toarray()\n",
    "q = np.array(q[0].tolist())\n",
    "new_user = np.copy(q)\n",
    "new_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of indices of books this user has actually rated\n",
    "indices = []\n",
    "for i in range(len(new_user)):\n",
    "    if new_user[i] != 0:\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial fit a new P and user_bias using trained Q and item_bias\n",
    "learning_rate = 0.01\n",
    "user_bias_reg = 0.1\n",
    "P_reg = 0.01\n",
    "iterations = 3000\n",
    "\n",
    "# TODO: figure out real golab bias, for now let's say 4.0\n",
    "global_bias = 4.0\n",
    "\n",
    "# TODO: set n_factors using input\n",
    "n_factors = 300\n",
    "\n",
    "# TODO: set cols using input\n",
    "cols = 10000\n",
    "\n",
    "# TODO: save item biases after training with Surprise\n",
    "item_bias = np.full(10000, 4.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.9645"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. get the user_bias for this user\n",
    "new_user_bias = np.mean(new_user) - global_bias\n",
    "new_user_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. set up new random P\n",
    "mu, sigma = 0, 0.1\n",
    "new_user_P = np.random.normal(mu, sigma, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Iteration 0: 6955.073276941169\n",
      "Loss at Iteration 300: 241.07787923746454\n",
      "Loss at Iteration 600: 213.50249897059186\n",
      "Loss at Iteration 900: 203.1392873652598\n",
      "Loss at Iteration 1200: 176.36352832644877\n",
      "Loss at Iteration 1500: 165.50753391571743\n",
      "Loss at Iteration 1800: 154.49330916410025\n",
      "Loss at Iteration 2100: 153.50912696578317\n",
      "Loss at Iteration 2400: 139.98865029371441\n",
      "Loss at Iteration 2700: 128.27372118446223\n"
     ]
    }
   ],
   "source": [
    "# 3. computer small number of iterations of SGD\n",
    "for iteration in range(iterations):\n",
    "    # 3.1 calculate loss with current components\n",
    "    errors = np.zeros(shape=(cols), dtype=np.float)\n",
    "    for i in indices:\n",
    "        rating = new_user[i]\n",
    "        # pred = global_bias + new_user_bias + item_bias[i] + np.dot(new_user_P, qi[i])\n",
    "        pred = new_user_bias + np.dot(new_user_P, qi[i])\n",
    "        errors[i] = rating - pred\n",
    "\n",
    "    # 3.2 periodically calculate total loss and output\n",
    "    if iteration % (iterations / 10) == 0:\n",
    "        total_loss = 0.0\n",
    "        for j in indices:\n",
    "            total_loss += pow(errors[j], 2)\n",
    "        print(\"Loss at Iteration {}: {}\".format(iteration, total_loss))\n",
    "\n",
    "    # 3.3 run single SGD iteration\n",
    "    new_user_P_target = np.copy(new_user_P)\n",
    "    new_user_bias_target = new_user_bias\n",
    "    \n",
    "    # pick random book user has rated\n",
    "    i = random.choice(indices)\n",
    "    \n",
    "    # update P\n",
    "    for f in range(n_factors):\n",
    "        p_update = learning_rate * (errors[i] * qi[i][f] - P_reg * new_user_P[f])\n",
    "        new_user_P_target[f] += p_update\n",
    "\n",
    "    # update user bias\n",
    "    ub_update = learning_rate * (errors[i] - user_bias_reg * new_user_bias)\n",
    "    new_user_bias_target += ub_update\n",
    "    \n",
    "    # 3.4 copy updated components back to original\n",
    "    new_user_P = np.copy(new_user_P_target)\n",
    "    new_user_bias = new_user_bias_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Drunkard's Walk: How Randomness Rules Our Lives\n",
      "Herzog\n",
      "The Handmaid's Tale\n",
      "Crash\n",
      "How the Light Gets In (Chief Inspector Armand Gamache, #9)\n",
      "Bad Monkey\n",
      "Hogwarts: An Incomplete and Unreliable Guide (Pottermore Presents, #3)\n",
      "And Then There Were None\n",
      "The Next Always (Inn BoonsBoro, #1)\n",
      "If You Could See Me Now\n",
      "The Work of Art in the Age of Its Technological Reproducibility, and Other Writings on Media\n",
      "Betrayal in Death (In Death, #12)\n",
      "The Structure of Scientific Revolutions\n",
      "The Hundred Thousand Kingdoms (Inheritance Trilogy, #1)\n",
      "Gemina (The Illuminae Files, #2)\n",
      "Mastering the Art of French Cooking\n",
      "Until I Die (Revenants, #2)\n",
      "ظل الأفعى\n",
      "Frigid (Frigid, #1)\n",
      "Breaking Night: A Memoir of Forgiveness, Survival, and My Journey from Homeless to Harvard\n",
      "The One (The Selection, #3)\n",
      "Clear and Present Danger (Jack Ryan Universe, #6)\n",
      "Villette\n",
      "Life Together: The Classic Exploration of Christian Community\n",
      "Children of God (The Sparrow, #2)\n"
     ]
    }
   ],
   "source": [
    "recs = get_top_n_recs(get_predictions(new_user_P, qi, new_user_bias), books, 25, new_user)\n",
    "for r in recs:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
